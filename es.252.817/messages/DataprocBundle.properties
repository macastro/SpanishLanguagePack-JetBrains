action.add.job.title=Enviar tarea
action.cancel.job.confirm.msg=¿Desea cancelar el proceso "{0}"?
action.cancel.job.title=Cancelar trabajo
action.clone.job.title=Clonar job
action.cluster.remove.confirm.msg=¿Eliminar clúster "{0}"?
action.cluster.start.confirm.msg=¿Iniciar el cluster "{0}"?
action.cluster.terminate.confirm.msg=¿Quieres terminar el cluster "{0}"?
action.confirm.title=Confirmar
action.delete.job.confirm.msg=¿Eliminar el job "{0}"?
action.delete.job.title=Eliminar tarea
action.open.stage.bucket=Abrir bucket de stage
action.sftp=Abrir SFTP en nodo
action.sftp.master.node=Abrir SFTP al nodo maestro
action.ssh=SSH hacia el nodo
action.ssh.master.node=Conectarse a nodo maestro vía SSH
add.job.title=Enviar tarea
add.new.submit.connection.label=Añadir conexión Dataproc...
cell.execution.finished.msg=La tarea "{0}" se ha completado, el estado es {1}.
cell.execution.finished.title=Trabajo de Dataproc
cluster.action.delete=Eliminar cluster
cluster.action.start=Iniciar clúster
cluster.action.stop=Detener clúster
cluster.info.config.autoscaling=Escalado automático:
cluster.info.config.master.node.desc=Nodo maestro:
cluster.info.config.metastore=Metastore de Dataproc:
cluster.info.config.monitoring=Monitoreo de integridad:
cluster.info.config.network=Red:
cluster.info.config.region=Región:
cluster.info.config.scheduled.deletion=Eliminación programada:
cluster.info.config.secure.boot=Arranque seguro:
cluster.info.config.vtpm=VTPM:
cluster.info.config.worker.node.desc=Nodo de proceso de trabajo:
cluster.info.config.zone=Zona disponible
cluster.info.image.created=Fecha creación:
cluster.info.image.version=Versión de la imagen
cluster.info.internal.ip=Sólo IP interna:
cluster.info.optional.components=Componentes opcionales:
cluster.info.summary.name=Nombre:
cluster.info.summary.state=State:
cluster.info.summary.state.details=Detalles de Estado:
cluster.info.summary.type=Tipo:
cluster.info.summary.uiid=ID universal del clúster:
cluster.tab.applications.title=Aplicaciones
cluster.tab.info.title=Información
cluster.tab.jobs.title=Tareas
cluster.tab.name=Cluster
cluster.tab.vb.instances.title=Instancias VM
data.clusterInfo.created=Creado
data.clusterInfo.id=ID
data.clusterInfo.name=Nombre
data.clusterInfo.region=region
data.clusterInfo.scheduledDeletion=Eliminación programada
data.clusterInfo.stagingBucket=Depósito provisional
data.clusterInfo.state=Estado
data.clusterInfo.totalWorkers=Total de procesos de trabajo
data.clusterInfo.zone=zona
data.jobInfo.cluster=cluster
data.jobInfo.elapsedTime=Tiempo transcurrido
data.jobInfo.id=ID
data.jobInfo.labels=Etiquetas
data.jobInfo.startTime=startTime
data.jobInfo.status=estado
data.jobInfo.type=Agrupar por Tipo
data.vm.instanceInfo.componentGateway=Gateway de componente
data.vm.instanceInfo.name=nombre
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=Nombre
data.web.interfaceInfo.role=Rol
datamanager.configuration=Configuración
datamanager.job.info=Información del Job
datamanager.labels=Etiquetas
datamanager.properties=Propiedades
datamanager.summary=Resumen
dataproc.error=Error de Dataproc
dataproc.error.cluster.must.be.started=El clúster debe estar iniciado.
dataproc.toolwindow.title=Dataproc GC
default.gcs.connection.name=Nombre del proyecto GC Dataproc
emr.remove.linked.connections.title=Conexiones enlazadas con Dataproc
error.connection.is.not.found=No se encontró conexión para Dataproc. Vuelve a crearla.
error.json.auth.limited.msg=Esta operación solo está disponible si se autentica en Dataproc mediante gcloud CLI
error.json.auth.limited.title=Operación no disponible
error.spark.is.not.found=El clúster no contiene un servidor de historial de Spark
exportable.DataprocSettings.presentable.name=Configuración de Big Data Tools Dataproc
exportable.DataprocSshKeyPaths.presentable.name=Configuración Dataproc SSH de Big Data Tools
group.name.dataproc=GC Dataproc
info.value.off=desactivado
instance.config.gpu.number=Cantidad de GPU
instance.config.local.ssd=SSD local
instance.config.machineType=Tipo máquina:
instance.config.primary.disk.size=Tamaño del disco principal:
instance.config.primary.disk.type=Tipo de disco principal:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=Etiquetas de cliente
job.info.cluster=Clúster:
job.info.continue.on.failure=Continuar con el error
job.info.elapsed.time=Tiempo transcurrido:
job.info.jobId=ID de trabajo:
job.info.jobUuid=UUID de trabajo:
job.info.max.restart.per.hour=Máximo de reinicios por hora:
job.info.max.restart.per.hour.hint=Dejar vacío para evitar reinicios automáticos ante fallos de trabajo.
job.info.open.job.files=Mostrar carpeta de trabajos en GCS
job.info.properties=Propiedades
job.info.query.file=Consulta:
job.info.query.file.value=Archivo de consulta:
job.info.query.text.value=Texto de consulta:
job.info.query.type=Fuente de consulta:
job.info.single.file.hint=Puede ser un archivo GCS con prefijo gs://, un archivo HDFS con prefijo hdfs:// en un clúster o un archivo local con prefijo file:// en un clúster
job.info.spark.additional.py.files=Archivos Python adicionales:
job.info.spark.additional.py.files.title=Seleccionar archivos Py adicionales
job.info.spark.additional.r.files=Archivos R adicionales:
job.info.spark.additional.r.files.title=Seleccionar archivos R adicionales
job.info.spark.archives=Archivos:
job.info.spark.archives.hint=Los archivos se extraen en el directorio de trabajo de Spark. Pueden ser archivos GCS con prefijo gs://, archivos HDFS con prefijo hdfs:// en el clúster o archivos locales en el clúster con prefijo file://. Los tipos de archivos admitidos incluyen: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Seleccionar archivos
job.info.spark.args=Argumentos:
job.info.spark.files=Archivos:
job.info.spark.jars=Jar:
job.info.spark.jars.hint=El JAR está incluido en CLASSPATH. Pueden usarse archivos GCS con prefijo gs://, archivos HDFS en el cluster con prefijo hdfs:// o archivos locales en el cluster con prefijo file://.
job.info.spark.jars.title=JAR
job.info.spark.main.class=Clase principal:
job.info.spark.main.py.file.title=Seleccionar archivo Py principal
job.info.spark.main.pyfile=Archivo principal de Python:
job.info.spark.main.r.file=Archivo R principal:
job.info.spark.main.r.file.title=Seleccionar el archivo principal R
job.info.start.date=Fecha inicio:
job.info.status=Estado:
job.info.status.details=Detalles del estado:
job.info.type=Tipo de tarea:
job.label.block.title=Etiqueta
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=Propiedades
job.pyspark.title=PySpark
job.query.file.dialog.title=Seleccionar archivo de consulta:
job.query.file.label=Archivo de consulta:
job.query.source.file=Archivo
job.query.source.text=Texto
job.query.source.type=Tipo de query:
job.query.text.hint=Consulta a ejecutar
job.query.text.label=Texto de consulta:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=activo
job.state.canceled=cancelado
job.state.done=Terminado
job.state.failed=estado=fallido
job.validation.file.archive={0} debe ser un tipo de archivo .jar, .tar, .tar.gz, .tgz, .zip.
job.validation.file.fs={0} debe ser un archivo con prefijo gs://, hdfs:// o file://
metainfo.cluster.id=ID:
metainfo.cluster.name=Nombre:
metainfo.cluster.status=Estado:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=La detección de la clase principal de {0} no es compatible.
settings.application.class.name.error.msg=Primero debes seleccionar un archivo jar
task.init.ssh.perform.cli.command=Ejecutando comando GCloud CLI...
task.init.ssh.title=Ejecución de CLI de Dataproc