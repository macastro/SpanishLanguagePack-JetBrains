alibaba.bucket.create.dialog.hierarchical.field=Espacio de nombres jerárquico
alibaba.bucket.create.dialog.versioning=Habilitar control de versiones
alibaba.custom.endpoint.text=Personalizado
alibaba.region.oss-ap-northeast-1=Japón (Tokio)
alibaba.region.oss-ap-northeast-2=Corea (Seúl)
alibaba.region.oss-ap-south-1=India (Bombay)
alibaba.region.oss-ap-southeast-1=Australia (Sydney) 1
alibaba.region.oss-ap-southeast-2=Australia (Sídney) 2
alibaba.region.oss-ap-southeast-3=Malasia (Kuala Lumpur)
alibaba.region.oss-ap-southeast-5=Indonesia (Yakarta)
alibaba.region.oss-ap-southeast-6=Filipinas (Manila)
alibaba.region.oss-ap-southeast-7=Tailandia (Bangkok)
alibaba.region.oss-cn-beijing=China (Pekín)
alibaba.region.oss-cn-chengdu=China (Chengdu)
alibaba.region.oss-cn-guangzhou=China (Guangzhou)
alibaba.region.oss-cn-hangzhou=China (Hangzhou)
alibaba.region.oss-cn-heyuan=China (Heyuan)
alibaba.region.oss-cn-hongkong=China (Hong Kong)
alibaba.region.oss-cn-huhehaote=China (Hohhot)
alibaba.region.oss-cn-nanjing=China (Nanjing - Región Local)
alibaba.region.oss-cn-qingdao=China (Qingdao)
alibaba.region.oss-cn-shanghai=China (Shanghái)
alibaba.region.oss-cn-shenzhen=China (Shenzhen)
alibaba.region.oss-cn-wulanchabu=China (Ulanchabu)
alibaba.region.oss-cn-zhangjiakou=China (Zhangjiakou)
alibaba.region.oss-eu-central-1=Alemania (Fráncfort)
alibaba.region.oss-eu-west-1=Región Reino Unido (Londres)
alibaba.region.oss-me-east-1=EAU (Dubái)
alibaba.region.oss-us-east-1=Estados Unidos (Virginia)
alibaba.region.oss-us-west-1=Estados Unidos (Silicon Valley)
alibaba.settings.credentials.file=Archivo de credenciales de Alibaba
alibaba.task.delete.bucket.text=Eliminando el contenedor {0}
alibaba.task.delete.directory.text=Eliminando directorio {0}
alibaba.task.delete.directory.text2={0} objetos eliminados
alibaba.task.delete.file.text=Eliminando el archivo {0}
azure.column.name.access.tier=Nivel de acceso
azure.rename.text2.indicator.deleting={0}: Eliminando {1}
bucket.name.is.empty.for.path=El nombre del bucket para la ruta "{0}" está vacío
cannot.find.linode.region=No se encuentra la región de {0}
cannot.open.read.stream.null.blob=No se puede abrir el flujo de lectura de null blob {0}
client.is.not.inited=El cliente no está inicializado
cloudflare.config.account.id.label=ID de cuenta:
cloudflare.config.account.id.text=ID de cuenta
cloudflare.config.custom.endpoint.label=Punto final:
cloudflare.config.selection.endpoint=Punto final personalizado
cloudflare.region.apac=Asia Pacífico
cloudflare.region.auto=Automático
cloudflare.region.eeur=Europa del Este
cloudflare.region.enam=América del Norte Oriental
cloudflare.region.oc=Oceanía
cloudflare.region.weur=Europa Occidental
cloudflare.region.wnam=América del Norte Occidental
connection.error.fs.and.user.not.found=No se encontró el sistema de archivos de la URI {0} y del usuario {1}
connection.error.hadoop.home.is.not.defined.full=HADOOPHOME no está definido. En Windows, se debe definir la variable de entorno HADOOPHOME o la propiedad Java hadoop.home.dir. Ver <a href="https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Hadoop Wiki</a> para más detalles.
connection.error.hadoop.no.native.drivers.full=No se han encontrado drivers nativos en HADOOPHOME. Revise el <a href="https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Hadoop Wiki</a> para obtener más detalles.
connection.error.root.path.must.be.non.empty=La ruta de raíz debe ser no vacía
controller.cluster.instances.error=Error al actualizar las instancias del clúster
controller.cluster.steps.error=ERROR actualización pasos del cluster
copy.failed=Fallo al copiar de {0} a {1}
custom.bucket.text.empty=bucket/carpeta, bucket2/carpeta/subcarpeta2, ...
custom.bucket.text.hint=Especificar una lista de raíces origen con separador "," (bucket1/folder1/folder2,bucket2/folder)
do.region.ams3=Amsterdam, Países Bajos
do.region.blr1=Berlín, Alemania
do.region.fra1=Frankfurt, Alemania
do.region.nyc3=Estados Unidos, Ciudad de Nueva York
do.region.sfo=EE.UU. San Francisco
do.region.sgp1=Singapur
do.region.syd1=Australia - Sydney
emr.cluster.filter=Filtrar por estado
emr.cluster.filter.limit=límit
emr.cluster.info.details=Mostrar como JSON
emr.cluster.terminate.cluster.message=¿Terminar el clúster {0}?
emr.cluster.terminate.cluster.title=Cluster está terminándose
emr.connection.creation=Creación de conexión EMR
emr.connection.warning.no.clusters=Conectado, no se encontraron clústeres
emr.connection.warning.no.clusters.desc=Se estableció la conexión, pero no se encontraron clústeres para la región seleccionada. Comprueba si la región es correcta.
emr.connection.warning.no.clusters.desc.window=No se han encontrado clústeres en la región "{0}". Compruebe la región.
emr.dialog.title.select.key.info.cancel=cancelar
emr.dialog.title.select.key.info.msg=Conexión requiere la creación de un túnel SSH. Seleccione el archivo de clave SSH del clúster para establecerlo.
emr.dialog.title.select.key.info.ok=Seleccionar clave SSH
emr.dialog.title.select.key.info.title=Necesitas una clave SSH
emr.dialog.title.select.key.ssh.file=Seleccionar archivo de clave SSH
emr.error=Error de AWS EMR
emr.error.remove.cluster=Error eliminando clúster
emr.error.start.cluster=Error al iniciar el clúster
emr.error.stop.cluster=Error deteniendo el clúster
emr.filter.text=Filtro:
emr.is.not.inited=Cliente EMR no inicializado
emr.key.storage.dialog.title=Almacén de claves SSH de EMR
emr.keys.settings.column.key.name=Nombre de la clave
emr.keys.settings.column.key.path=ruta
emr.keys.settings.label=Clave SSH:
emr.keys.settings.table.empty=Llaves SSH no proporcionadas
emr.label.choose.key.file.for.aws.pair=Seleccionar archivo de claves para el par AWS {0}
emr.remove.linked.connections.action=Eliminar conexiones
emr.remove.linked.connections.desc=¿Desea eliminar las conexiones creadas para EMR?
emr.remove.linked.connections.title=Conexiones EMR
emr.spark.submit=Envío de EMR Spark
emr.spark.submit.editor.args=Argumentos:
emr.spark.submit.editor.jar.loc=Ubicación del JAR:
emr.spark.submit.editor.name=Nombre:
emr.step.details=Mostrar detalles del paso
emr.step.mapper.choose=Seleccionar Mapper
emr.step.reducer.choose=Escoger Reducer
emr.step.s3.input.choose=Seleccionar entrada de S3
emr.step.s3.output.choose=Elegir salida S3
emr.step.script.choose=Seleccionar ubicación del script en S3
emr.toolwindow.title=AWS EMR
error.krb5.conf=Fallo de autenticación de Kerberos. Intenta añadir "allowweakcrypto = true" a krb5.conf
error.object.summary.is.not.found=No se encuentra el resumen del objeto {0}
file.info.access.blob.type=Tipo blob
file.info.access.content.type=Tipo de Contenido
file.info.access.tier=Nivel de acceso
file.info.access.tier.modified=Fecha última modificación capa acceso
gcs.buckets.source=Fuente de depósitos:
gcs.connection.browse.title=Seleccionar credenciales JSON
gcs.connection.error.bucket.validation1=El nombre del bucket debe contener de 3 a 63 caracteres. Los nombres que incluyen puntos pueden contener un máximo de 222 caracteres; sin embargo, cada componente separado por puntos no debe superar los 63 caracteres.
gcs.connection.error.bucket.validation2=El nombre sólo puede contener letras minúsculas, números, guiones (-), guiones bajos (_) y puntos (.).
gcs.connection.error.bucket.validation3=El nombre del bucket debe comenzar y terminar con un número o letra.
gcs.connection.error.bucket.validation4=El nombre del bucket no puede expresarse como una dirección IP de forma decimal separada por puntos (por ejemplo, 192.168.5.4).
gcs.connection.error.bucket.validation5=El nombre del depósito no puede comenzar con prefijo "goog"
gcs.connection.error.bucket.validation6=El nombre del Bucket no puede contener "google" o una palabra de mal escrita similar a google, como "g00gle"
gcs.connection.error.cred.file.not.selected=Se debe seleccionar un archivo de credenciales para la cuenta
gcs.connection.error.file.not.exists=El archivo no existe
gcs.custom.url=Url personalizada:
gcs.json.location.emptyText=Ubicación de Cloud Storage JSON
gcs.multibucket.update.text=¡Google Cloud Storage tiene soporte para múltiples buckets! Puede configurarlos en las opciones de conexión.
gcs.multibucket.update.title=Nuevas funcionalidades de GCS en BigDataTools
gcs.progress.details.deleting=Eliminando {0}
gcs.project.id=Id. del proyecto:
gcs.project.id.emptyText=ID de proyecto de reemplazo opcional
gcs.project.id.hint=Mostrar bucket con ID de proyecto especial
gcs.public.hint=Dejar vacío para buckets públicos
gcs.sdk.install=No se encontró Google Cloud SDK. <a>Instalar</a>
gcs.sdk.update=Google Cloud SDK está desactualizado. <a>Actualizar</a>
group.name.alibaba=Alibaba OSS
group.name.azure=Azure
group.name.cloudflare=Cloudflare R2
group.name.dospaces=DigitalOcean Spaces
group.name.emr=AWS EMR
group.name.gcs=Google Cloud Storage
group.name.hdfs.java=HDFS
group.name.linode=Linode
group.name.minio=MinIO
group.name.s3=AWS S3
group.name.yandex=Almacenamiento de objetos Yandex
group.names.hdfs.data=Problemas de HDFS
hdfs.column.name.access.time=Tiempo de acceso
hdfs.column.name.block.size=Tamaño de bloque
hdfs.column.name.group=Grupo
hdfs.column.name.is.encrypted=cifrado
hdfs.column.name.is.isErasureCoded=Decodificación de borrado
hdfs.column.name.is.isSnapshotEnabled=Instantáneas
hdfs.column.name.owner=propietario
hdfs.column.name.permission=Permisos
hdfs.column.name.replications=Replicaciones
hdfs.config.path.does.not.exist=Ruta configurada no existe
hdfs.config.path.no.xmls.found=El directorio proporcionado no contiene ningún archivo XML
hdfs.config.path.not.empty=La ruta de configuración no debe estar vacía
hdfs.config.path.should.be.directory=La ruta de configuración debe apuntar a un directorio
hdfs.config.path.title=Ruta de configuración de la API de Java
hdfs.field.root.path=rutaraiz
hdfs.file.info.label.accessTime=Fecha de acceso:
hdfs.file.info.label.block.size=Tamaño de bloque:
hdfs.file.info.label.group=Grupo:
hdfs.file.info.label.isEncrypted=Es cifrado:
hdfs.file.info.label.isErasureCoded=Código de borrado utilizado:
hdfs.file.info.label.isSnapshotEnabled=Snapshot habilitado:
hdfs.file.info.label.modificationTime=Hora de modificación:
hdfs.file.info.label.owner=Propietario:
hdfs.file.info.label.permission=Permisos:
hdfs.file.info.label.replication=replicación:
hdfs.file.info.label.size=tamaño:
hdfs.is.not.inited=La conexión Hdfs no ha sido inicializada
hdfs.java.config.source=Fuente de configuración:
hdfs.java.driver.home.path=Ruta home del controlador:
hdfs.no.xmls.in.directory=No hay archivos XML en la raíz de configuración
hdfs.property.source.directory=Directorio de origen
hdfs.property.source.explicit=Personalizado
hdfs.root.folder.does.not.exist=La carpeta raíz ''{0}'' no existe
hdfs.ssh.tunnel.ssh.operation.not.supported=Operación vía túnel SSH no es soportada
inspection.java.custom.hdfs.format.display.name=Resaltado personalizado de formato de archivo HDFS
inspection.java.invalid.file.path.display.name=Resaltar ruta de archivo HDFS no válida
inspection.kotlin.custom.hdfs.format.display.name=Resaltado de formato de archivo HDFS personalizado
inspection.kt.invalid.file.path.display.name=Resaltado de rutas de archivo HDFS no válidas
inspection.non.serializable.data.in.scope.display.name=Resaltar datos no serializables en una tarea Spark
inspection.scala.custom.hdfs.format.display.name=Destacar formato de archivo HDFS personalizado
inspection.scala.invalid.hdfs.file.path.display.name=Resaltado de rutas de archivos HDFS no válidas
invalid.format.inspection.description=Inspección de resaltado del formato hdfs personalizado. De forma predeterminada se espera parquet, orc, sequence, json, csv o texto.
invalid.format.inspection.template=Formato de plantilla personalizado inesperado
java.wrong.path.inspection.description=Resalta rutas hdfs inválidas en el código Java
kerberos.type.credentials=Credencial
kerberos.type.disabled=Desactivado
kerberos.type.keytab=Keytab
kerberos.type.subject=Configuración JAAS (experto)
kotlin.wrong.path.inspection.description=Resalta rutas hdfs no válidas en código Kotlin
linode.region.ap-south=Singapur
linode.region.br-gru-1=São Paulo, Brazil
linode.region.eu-central=Frankfurt, Alemania
linode.region.fr-par-1=Francia - París
linode.region.id-cgk-1=Yakarta, Indonesia
linode.region.in-maa-1=Chennai, India
linode.region.it-mil-1=Milan, Italia
linode.region.jp-osa-1=Osaka, Japón
linode.region.nl-ams-1=Ámsterdam, Países Bajos
linode.region.se-sto-1=Estocolmo, Suecia
linode.region.us-east=EE. UU., Nueva Jersey, Newark
linode.region.us-iad-1=EE.UU. Región de Washington, DC
linode.region.us-lax-1=Estados Unidos, Los Ángeles, CA
linode.region.us-mia-1=Estados Unidos, Florida, Miami
linode.region.us-ord-1=Chicago, Illinois, Estados Unidos
linode.region.us-sea-1=Seattle, Washington, USA
linode.region.us-southeast=Atlanta, Georgia, EE. UU.
metainfo.headers.empty=Sin cabeceras personalizadas
metainfo.headers.key=Clave
metainfo.headers.value=Valor
metainfo.section.custom.headers=Encabezados
minio.region.text.empty=Utilizar valor predeterminado
move.failed=Error al mover desde {0} a {1}.
notification.group.orc.files=Archivos ORC
oss.file.info.label.hns.status=Espacio de nombres jerárquico:
oss.file.info.label.hns.status.disabled=desactivado
oss.file.info.label.type=Content-Type:
rfs.create.bucket.message=Crear bucket
s3.bucket.text.empty=Todos los buckets son visibles
s3.bucket.text.hint=Si este campo está vacío, todos los buckets serán visibles<br>Para trabajar con un solo bucket, ingresa el nombre del bucket y selecciona el tipo de filtro "Coincide con"<br>Separa los buckets con "," (bucket1,bucket2)
s3.column.name.etag=ETag
s3.column.name.metadata=Metadatos
s3.column.name.storage.class=Clase de almacenamiento
s3.connection.error.ssh.without.endpoint=Para usar un túnel SSH, especifique un punto final para el controlador
s3.empty.directories.not.allowed=No se permiten directorios vacíos
s3.multibucket.open.settings=Abrir Configuración
s3.multibucket.update.text=Los S3 compatibles con el almacenamiento admiten varios buckets.  Puedes configurarlos en las configuraciones de conexión.
s3.multibucket.update.title=Nueva funcionalidad para S3 en BigDataTools
scala.serializable.scope.inspection.description=Resalta valores no serializables usados dentro del ámbito de la tarea spark que provocan una excepción de tiempo de ejecución.
scala.serializable.scope.inspection.warning=<html>Valor no serializable de tipo {1} en el ámbito de Spark {2}</html>
scala.wrong.path.inspection.description=Resalta rutas hdfs no válidas en código Scala
settings.alibaba.region=Región:
settings.azure.auth.type=Tipo de autenticación:
settings.azure.connection.string=Cadena de conexión:
settings.azure.container=Contenedor:
settings.azure.endpoint=Punto de enlace:
settings.azure.password=Contraseña:
settings.azure.sas.token=Token SAS:
settings.azure.user.key=Clave:
settings.azure.username=Usuario:
settings.bucket.filter=Filtro de depósito:
settings.bucket.filter.type=Tipo de filtro:
settings.buckets.custom.list=Lista raíz definida por el usuario
settings.buckets.hint=<html><b>Todos los buckets en la cuenta</b> - Ejecuta una solicitud tipo <it>list buckets</it>. Se permite filtrar la lista de bucket de resultados.<br><br><b>Raíz personalizada</b> - Solicita directamente la raíz seleccionada, lo que permite especificar no solo un bucket, sino también la ruta completa al directorio.</html>
settings.buckets.user.list=Todos los buckets en la cuenta
settings.config.from.folder=Configuración analizada:
settings.config.path=Ruta de configuración:
settings.custom.roots=Raíces:
settings.generate.kerberos=Kerberos
settings.hdfs.auth.type=Autentificación:
settings.hdfs.kerberos.type=Método de autenticación:
settings.hdfs.kinit=Utilizar kinit cache
settings.hdfs.url=URI del clúster:
settings.hdfs.username=Nombre de usuario Hadoop:
settings.hdfs.username.hint=Nombre de usuario para iniciar sesión en el servidor. Si no se especifica, se utilizará la variable de entorno <i>HAD00PUSERNAME</i>. Si no se define esta variable, se utilizará la propiedad <i>user.name</i>. Si se habilita Kerberos, se sobrescribirán estos tres valores.
settings.kerberos.auth=Autenticación:
settings.kerberos.auth.kerberos=Kerberos
settings.kerberos.auth.none=ninguno
settings.minio.endpoint=Endpoint:
settings.properties=Propiedades avanzadas:
settings.s3.bucket.filter.by.region=Solo buckets en regiones seleccionadas
settings.s3.custom.endpoint=Punto final:
settings.s3.custom.region=Región:
settings.s3.custom.region.hint=Usar según sea necesario
settings.s3.region=Región:
settings.s3.region.group=AWS S3
settings.s3.selection.endpoint=Almacenamiento compatible con S3
settings.undefined.path=<No inicializado>
settings.validation.kerberos.keytab.error=Debe especificar el keytab y el principal
settings.validation.kerberos.password.error=Debe especificar el principal y contraseña
setup.video.tutor=Tutoriales de configuración de la conexión en vídeo
ssh.additional.info=SSH tunnellings <b>sólo funcionan con operaciones de nodo de nombre</b>: listando ficheros, obteniendo metadatos. <br><br>
ssh.additional.label=(Solo solicitudes NameNode)
wrong.region=No se encuentra la región "{0}"