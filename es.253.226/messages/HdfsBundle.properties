alibaba.bucket.create.dialog.hierarchical.field=Espacio de nombres jerárquico
alibaba.bucket.create.dialog.versioning=Habilitar control de versiones
alibaba.custom.endpoint.text=Personalizado
alibaba.region.oss-ap-northeast-1=Japón (Tokio)
alibaba.region.oss-ap-northeast-2=Corea del Sur (Seúl)
alibaba.region.oss-ap-south-1=India (Mumbai)
alibaba.region.oss-ap-southeast-1=Australia (Sídney) 1
alibaba.region.oss-ap-southeast-2=Australia (Sídney) 2
alibaba.region.oss-ap-southeast-3=Malasia (Kuala Lumpur)
alibaba.region.oss-ap-southeast-5=Indonesia (Yakarta)
alibaba.region.oss-ap-southeast-6=Filipinas (Manila)
alibaba.region.oss-ap-southeast-7=Tailandia (Bangkok)
alibaba.region.oss-cn-beijing=China (Pekín)
alibaba.region.oss-cn-chengdu=China (Chengdu)
alibaba.region.oss-cn-guangzhou=China (Guangzhou)
alibaba.region.oss-cn-hangzhou=China (Hangzhou)
alibaba.region.oss-cn-heyuan=China (Heyuan)
alibaba.region.oss-cn-hongkong=China (Hong Kong)
alibaba.region.oss-cn-huhehaote=China (Hohhot)
alibaba.region.oss-cn-nanjing=China (Nanjing - Región local)
alibaba.region.oss-cn-qingdao=China (Qingdao)
alibaba.region.oss-cn-shanghai=China (Shanghái)
alibaba.region.oss-cn-shenzhen=China (Shenzhen)
alibaba.region.oss-cn-wulanchabu=China (Ulanqab)
alibaba.region.oss-cn-zhangjiakou=China (Zhangjiakou)
alibaba.region.oss-eu-central-1=Alemania (Frankfurt)
alibaba.region.oss-eu-west-1=Reino Unido (Londres)
alibaba.region.oss-me-east-1=Emiratos Árabes Unidos (Dubái)
alibaba.region.oss-us-east-1=EE. UU. (Virginia)
alibaba.region.oss-us-west-1=EE. UU. (Silicon Valley)
alibaba.settings.credentials.file=Archivo de credenciales de Alibaba
alibaba.task.delete.bucket.text=Eliminando el bucket {0}
alibaba.task.delete.directory.text=Eliminando el directorio {0}
alibaba.task.delete.directory.text2=Se han eliminado {0} objetos
alibaba.task.delete.file.text=Eliminando el archivo {0}
azure.column.name.access.tier=Nivel de acceso
azure.rename.text2.indicator.deleting={0}: eliminando {1}
bucket.name.is.empty.for.path=El nombre del bucket para la ruta "{0}" está vacío
cannot.find.linode.region=No se puede encontrar la región de {0}
cannot.open.read.stream.null.blob=No se puede abrir el flujo de lectura para el blob nulo {0}
client.is.not.inited=El cliente no se ha inicializado
cloudflare.config.account.id.label=ID de la cuenta:
cloudflare.config.account.id.text=ID de la cuenta
cloudflare.config.custom.endpoint.label=Endpoint:
cloudflare.config.selection.endpoint=Endpoint personalizado
cloudflare.region.apac=Asia-Pacífico
cloudflare.region.auto=Automático
cloudflare.region.eeur=Europa del Este
cloudflare.region.enam=Norteamérica Este
cloudflare.region.oc=Oceanía
cloudflare.region.weur=Europa Occidental
cloudflare.region.wnam=Norteamérica occidental
connection.error.fs.and.user.not.found=No se encontró el sistema de archivos para la URI {0} y el usuario {1}
connection.error.hadoop.home.is.not.defined.full=HADOOP_HOME no está definido. En Windows, debe definir la variable de entorno HADOOP_HOME o la propiedad de Java hadoop.home.dir. Consulte la <a href="https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Hadoop Wiki</a> para obtener más detalles.
connection.error.hadoop.no.native.drivers.full=No se pudieron encontrar controladores nativos en HADOOP_HOME. Consulte la <a href="https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems">Wiki de Hadoop</a> para obtener más detalles.
connection.error.root.path.must.be.non.empty=La ruta raíz no puede estar vacía
controller.cluster.instances.error=Error al actualizar las instancias del clúster
controller.cluster.steps.error=Error al actualizar los pasos del clúster
copy.failed=Error al copiar de {0} a {1}.
custom.bucket.text.empty=bucket/carpeta,bucket2/carpeta/subcarpeta2,…
custom.bucket.text.hint=Use el separador ',' para especificar la lista de raíces de origen (bucket1/folder1/folder2,bucket2/folder)
do.region.ams3=Ámsterdam, Países Bajos
do.region.blr1=Berlín, Alemania
do.region.fra1=Frankfurt, Alemania
do.region.nyc3=Nueva York, EE. UU.
do.region.sfo=San Francisco, EE. UU.
do.region.sgp1=Singapur
do.region.syd1=Sídney, Australia
emr.cluster.filter=Filtrar por estado
emr.cluster.filter.limit=Límite
emr.cluster.info.details=Mostrar como JSON
emr.cluster.terminate.cluster.message=¿Desea terminar el clúster {0}?
emr.cluster.terminate.cluster.title=Terminando clúster
emr.connection.creation=Creación de conexión de EMR
emr.connection.warning.no.clusters=Conectado. No se encontraron clústeres
emr.connection.warning.no.clusters.desc=Se ha establecido la conexión, pero no se encontraron clústeres en la región seleccionada. Compruebe si la región es correcta.
emr.connection.warning.no.clusters.desc.window=No se encontraron clústeres en la región {0}. Compruebe la región.
emr.dialog.title.select.key.info.cancel=Cancelar
emr.dialog.title.select.key.info.msg=La conexión requiere crear un túnel SSH. Para configurarlo, seleccione el archivo de clave SSH del clúster.
emr.dialog.title.select.key.info.ok=Seleccionar clave SSH
emr.dialog.title.select.key.info.title=Se requiere una clave SSH
emr.dialog.title.select.key.ssh.file=Seleccionar archivo de clave SSH
emr.error=Excepción de AWS EMR
emr.error.remove.cluster=Error al eliminar el clúster
emr.error.start.cluster=Error al iniciar el clúster
emr.error.stop.cluster=Error al detener el clúster
emr.filter.text=Filtro:
emr.is.not.inited=El cliente EMR no se ha inicializado
emr.key.storage.dialog.title=Almacén de claves SSH de EMR
emr.keys.settings.column.key.name=Nombre de la clave
emr.keys.settings.column.key.path=Ruta
emr.keys.settings.label=Claves SSH:
emr.keys.settings.table.empty=No se proporcionaron claves SSH
emr.label.choose.key.file.for.aws.pair=Seleccionar archivo de clave para el par {0} de AWS
emr.remove.linked.connections.action=Eliminar conexiones
emr.remove.linked.connections.desc=¿Desea eliminar las conexiones creadas para EMR?
emr.remove.linked.connections.title=Conexiones EMR
emr.spark.submit=Envío de Spark de EMR
emr.spark.submit.editor.args=Argumentos:
emr.spark.submit.editor.jar.loc=Ubicación del JAR:
emr.spark.submit.editor.name=Nombre:
emr.step.details=Mostrar detalles del paso
emr.step.mapper.choose=Seleccionar Mapper
emr.step.reducer.choose=Seleccionar Reducer
emr.step.s3.input.choose=Seleccionar entrada de S3
emr.step.s3.output.choose=Seleccionar salida de S3
emr.step.script.choose=Seleccionar la ubicación del script en S3
emr.toolwindow.title=AWS EMR
error.krb5.conf=No se pudo autorizar mediante Kerberos. Intente añadir "allow_weak_crypto = true" a krb5.conf
error.object.summary.is.not.found=No se encontró el resumen del objeto para {0}
file.info.access.blob.type=Tipo de Blob
file.info.access.content.type=Tipo de contenido
file.info.access.tier=Nivel de acceso
file.info.access.tier.modified=Última modificación del nivel de acceso
gcs.buckets.source=Origen de buckets:
gcs.connection.browse.title=Seleccionar JSON de credenciales
gcs.connection.error.bucket.validation1=El nombre del bucket debe tener entre 3 y 63 caracteres. Los nombres que contienen puntos pueden tener hasta 222 caracteres, pero cada componente separado por puntos no debe superar los 63 caracteres.
gcs.connection.error.bucket.validation2=El nombre solo puede contener letras minúsculas, números, guiones (-), guiones bajos (_) y puntos (.).
gcs.connection.error.bucket.validation3=El nombre del bucket debe comenzar y finalizar con un número o una letra.
gcs.connection.error.bucket.validation4=El nombre del bucket no puede representarse como una dirección IP en formato decimal separado por puntos (p. ej., 192.168.5.4).
gcs.connection.error.bucket.validation5=El nombre del bucket no puede empezar con el prefijo "goog".
gcs.connection.error.bucket.validation6=El nombre del bucket no puede contener "google" ni errores de ortografía similares, como "g00gle".
gcs.connection.error.cred.file.not.selected=Debe seleccionar un archivo de credenciales para la cuenta
gcs.connection.error.file.not.exists=El archivo no existe
gcs.custom.url=Url personalizada:
gcs.json.location.emptyText=Ubicación del JSON de Cloud Storage
gcs.multibucket.update.text=¡Google Cloud Storage ya admite múltiples buckets! Puede configurarlos en los ajustes de conexión.
gcs.multibucket.update.title=Nuevas funciones de GCS para BigDataTools
gcs.progress.details.deleting=Eliminando {0}
gcs.project.id=ID del proyecto:
gcs.project.id.emptyText=ID de proyecto de sobrescritura opcional
gcs.project.id.hint=Muestra los buckets de un ID de proyecto especial
gcs.public.hint=Dejar vacío para buckets públicos
gcs.sdk.install=No se encontró Google Cloud SDK. <a>Instalar</a>
gcs.sdk.update=Google Cloud SDK está desactualizado. <a>Actualizar</a>
group.name.alibaba=Alibaba OSS
group.name.azure=Azure
group.name.cloudflare=Cloudflare R2
group.name.dospaces=DigitalOcean Spaces
group.name.emr=AWS EMR
group.name.gcs=Google Cloud Storage
group.name.hdfs.java=HDFS
group.name.linode=Linode
group.name.minio=MinIO
group.name.s3=AWS S3
group.name.yandex=Almacenamiento de objetos de Yandex
group.names.hdfs.data=Problemas de HDFS
hdfs.column.name.access.time=Hora de acceso
hdfs.column.name.block.size=Tamaño del bloque
hdfs.column.name.group=Grupo
hdfs.column.name.is.encrypted=Cifrado
hdfs.column.name.is.isErasureCoded=Codificación de borrado
hdfs.column.name.is.isSnapshotEnabled=Instantánea
hdfs.column.name.owner=Propietario
hdfs.column.name.permission=Permisos
hdfs.column.name.replications=Réplicas
hdfs.config.path.does.not.exist=El directorio especificado no existe.
hdfs.config.path.no.xmls.found=El directorio especificado no contiene ningún archivo XML.
hdfs.config.path.not.empty=La ruta de configuración no debe estar vacía.
hdfs.config.path.should.be.directory=La ruta de configuración debe apuntar a un directorio.
hdfs.config.path.title=Ruta de configuración de la API de Java
hdfs.field.root.path=Ruta raíz
hdfs.file.info.label.accessTime=Hora de acceso:
hdfs.file.info.label.block.size=Tamaño del bloque:
hdfs.file.info.label.group=Grupo:
hdfs.file.info.label.isEncrypted=Cifrado:
hdfs.file.info.label.isErasureCoded=Codificación de borrado:
hdfs.file.info.label.isSnapshotEnabled=Snapshot habilitado:
hdfs.file.info.label.modificationTime=Fecha de modificación:
hdfs.file.info.label.owner=Propietario:
hdfs.file.info.label.permission=Permiso:
hdfs.file.info.label.replication=Replicación:
hdfs.file.info.label.size=Tamaño:
hdfs.is.not.inited=La conexión Hdfs no está inicializada
hdfs.java.config.source=Fuente de configuración:
hdfs.java.driver.home.path=Ruta principal del controlador:
hdfs.no.xmls.in.directory=No hay archivos XML en la raíz de configuración
hdfs.property.source.directory=Carpeta de configuración
hdfs.property.source.explicit=Personalizado
hdfs.root.folder.does.not.exist=La carpeta raíz {0} no existe
hdfs.ssh.tunnel.ssh.operation.not.supported=No se admiten operaciones a través de un túnel SSH.
inspection.java.custom.hdfs.format.display.name=Resaltado personalizado de formato de archivo HDFS
inspection.java.invalid.file.path.display.name=Resaltar ruta de archivo HDFS no válida
inspection.kotlin.custom.hdfs.format.display.name=Resaltado de formato de archivo HDFS personalizado
inspection.kt.invalid.file.path.display.name=Resaltado de rutas de archivo HDFS no válidas
inspection.non.serializable.data.in.scope.display.name=Resaltar datos no serializables en una tarea Spark
inspection.scala.custom.hdfs.format.display.name=Destacar formato de archivo HDFS personalizado
inspection.scala.invalid.hdfs.file.path.display.name=Resaltado de rutas de archivos HDFS no válidas
invalid.format.inspection.description=Inspección de resaltado del formato hdfs personalizado. De forma predeterminada se espera parquet, orc, sequence, json, csv o texto.
invalid.format.inspection.template=Formato de plantilla personalizado inesperado
java.wrong.path.inspection.description=Resalta rutas hdfs inválidas en el código Java
kerberos.type.credentials=Contraseña
kerberos.type.disabled=Deshabilitado
kerberos.type.keytab=Keytab
kerberos.type.subject=Configuración de JAAS (avanzado)
kotlin.wrong.path.inspection.description=Resalta rutas hdfs no válidas en código Kotlin
linode.region.ap-south=Singapur
linode.region.br-gru-1=São Paulo, Brasil
linode.region.eu-central=Fráncfort, Alemania
linode.region.fr-par-1=París, Francia
linode.region.id-cgk-1=Yakarta, Indonesia
linode.region.in-maa-1=Chennai, India
linode.region.it-mil-1=Milán, Italia
linode.region.jp-osa-1=Osaka, Japón
linode.region.nl-ams-1=Ámsterdam, Países Bajos
linode.region.se-sto-1=Estocolmo, Suecia
linode.region.us-east=Newark, Nueva Jersey, EE. UU.
linode.region.us-iad-1=Washington, D.C., EE. UU.
linode.region.us-lax-1=Los Ángeles, California, EE. UU.
linode.region.us-mia-1=Miami, Florida, EE. UU.
linode.region.us-ord-1=Chicago, Illinois, EE. UU.
linode.region.us-sea-1=Seattle, Washington, EE. UU.
linode.region.us-southeast=Atlanta, Georgia, EE. UU.
metainfo.headers.empty=Sin encabezados personalizados
metainfo.headers.key=Clave
metainfo.headers.value=Valor
metainfo.section.custom.headers=Cabeceras
minio.region.text.empty=Usar valor predeterminado
move.failed=No se pudo mover de {0} a {1}.
notification.group.orc.files=Archivos ORC
oss.file.info.label.hns.status=Espacio de nombres jerárquico:
oss.file.info.label.hns.status.disabled=Deshabilitado
oss.file.info.label.type=Tipo de contenido:
rfs.create.bucket.message=Crear bucket
s3.bucket.text.empty=Todos los buckets son visibles
s3.bucket.text.hint=Si este campo está vacío, todos los buckets serán visibles<br>Ingrese el nombre del bucket y seleccione el tipo de filtro "Coincidencia" para trabajar con un solo bucket<br>Use "," para separar los buckets (bucket1, bucket2)
s3.column.name.etag=ETag
s3.column.name.metadata=Metadatos
s3.column.name.storage.class=Clase de almacenamiento
s3.connection.error.ssh.without.endpoint=Para utilizar un túnel SSH, especifique un endpoint para el controlador
s3.empty.directories.not.allowed=No se permite crear directorios vacíos.
s3.multibucket.open.settings=Abrir configuración
s3.multibucket.update.text=El almacenamiento compatible con S3 admite varios buckets. Puede configurarlos en los ajustes de conexión.
s3.multibucket.update.title=Nuevas funciones de S3 en BigDataTools
scala.serializable.scope.inspection.description=Resalta valores no serializables usados dentro del ámbito de la tarea spark que provocan una excepción de tiempo de ejecución.
scala.serializable.scope.inspection.warning=<html>Valor no serializable de tipo {1} en el ámbito de Spark {2}</html>
scala.wrong.path.inspection.description=Resalta rutas hdfs no válidas en código Scala
settings.alibaba.region=Región:
settings.azure.auth.type=Tipo de autenticación:
settings.azure.connection.string=Cadena de conexión:
settings.azure.container=Contenedor:
settings.azure.endpoint=Punto de conexión:
settings.azure.password=Contraseña:
settings.azure.sas.token=Token SAS:
settings.azure.user.key=Clave:
settings.azure.username=Nombre de usuario:
settings.bucket.filter=Filtro de bucket:
settings.bucket.filter.type=Tipo de filtro:
settings.buckets.custom.list=Raíces personalizadas
settings.buckets.hint=<html><b>Todos los buckets de la cuenta</b> - Ejecuta una solicitud de tipo <it>list buckets</it>. Permite filtrar la lista de buckets resultante.<br><br><b>Raíces personalizadas</b> - Solicita directamente las raíces seleccionadas, lo que permite especificar no solo el bucket, sino también la ruta completa al directorio.</html>
settings.buckets.user.list=Todos los buckets de la cuenta
settings.config.from.folder=Configuración analizada:
settings.config.path=Ruta de configuración:
settings.custom.roots=Raíces:
settings.generate.kerberos=Kerberos
settings.hdfs.auth.type=Autenticación:
settings.hdfs.kerberos.type=Método de autenticación:
settings.hdfs.kinit=Usar caché de kinit
settings.hdfs.url=URI del clúster:
settings.hdfs.username=Nombre de usuario de Hadoop:
settings.hdfs.username.hint=Nombre de usuario para iniciar sesión en el servidor. Si no se especifica, se utiliza la variable de entorno <i>HAD00P_USER_NAME</i>. Si esta variable no está definida, se utiliza la propiedad <i>user.name</i>. Si Kerberos está habilitado, sobrescribirá estos tres valores.
settings.kerberos.auth=Autenticación:
settings.kerberos.auth.kerberos=Kerberos
settings.kerberos.auth.none=Ninguno
settings.minio.endpoint=Endpoint:
settings.properties=Configuración avanzada:
settings.s3.bucket.filter.by.region=Solo buckets de la región seleccionada
settings.s3.custom.endpoint=Punto de conexión:
settings.s3.custom.region=Región:
settings.s3.custom.region.hint=Usar cuando sea necesario
settings.s3.region=Región:
settings.s3.region.group=AWS S3
settings.s3.selection.endpoint=Almacenamiento compatible con S3
settings.undefined.path=<No inicializado>
settings.validation.kerberos.keytab.error=Debe especificar el keytab y el principal
settings.validation.kerberos.password.error=Debe especificar el principal y la contraseña
setup.video.tutor=Tutoriales de configuración de la conexión en vídeo
ssh.additional.info=El túnel SSH <b>solo funciona para operaciones con el NameNode</b>: listar archivos, obtener metainformación.<br><br>
ssh.additional.label=(Solo operaciones de NameNode)
wrong.region=No se encontró la región {0}
