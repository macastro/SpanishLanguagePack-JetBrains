action.show.execution.graph=Mostrar
action.text.filter.state=Estado del filtro
action.titile.copy.logs=Copiar registros
app.run.by.me=Enviado por mí
applications.filter.finished=Finalizado
applications.filter.limit=Límite
applications.filter.name=Filtro:
applications.filter.started=Iniciado
applications.tab.console=Consola
applications.tab.details=Detalles
applications.tab.environment=Entorno
applications.tab.executors=Ejecutores
applications.tab.info=Información
applications.tab.jobs=Trabajos
applications.tab.sql=SQL
applications.tab.stages=Etapas
applications.tab.storage=Almacenamiento
applications.tab.storage.distribution=Distribución de datos
applications.tab.storage.distribution.toggle.hint=Cambiar la visibilidad de la tabla de distribución de datos del almacenamiento seleccionado
applications.tab.storage.partitions=Particiones
applications.tab.storage.partitions.toggle.hint=Cambiar la visibilidad de la tabla de particiones del almacenamiento seleccionado
column.show.logs=Registros
connection.defaultName=Monitoreo de Spark {0}
connection.group.name.spark=Spark
data.ExecutorSummary.active=Activo
data.ExecutorSummary.activeTasks=Tareas activas
data.ExecutorSummary.addTime=Fecha de adición
data.ExecutorSummary.address=Dirección
data.ExecutorSummary.attributes=Atributos
data.ExecutorSummary.blacklisted=En lista negra
data.ExecutorSummary.blacklistedInStages=Incluido en la lista negra en las etapas
data.ExecutorSummary.completedTasks=Tareas completadas
data.ExecutorSummary.diskUsed=Disco usado
data.ExecutorSummary.failedTasks=Tareas fallidas
data.ExecutorSummary.id=ID
data.ExecutorSummary.maxMemory=Memoria máxima
data.ExecutorSummary.maxTasks=Tareas máximas
data.ExecutorSummary.memoryMetrics=Métricas de memoria
data.ExecutorSummary.memoryUsed=Memoria utilizada
data.ExecutorSummary.rddBlocks=Bloques RDD
data.ExecutorSummary.removeReason=Motivo de la eliminación
data.ExecutorSummary.removeTime=Hora de eliminación
data.ExecutorSummary.resourceProfileId=ID de perfil de recursos
data.ExecutorSummary.resources=Recursos
data.ExecutorSummary.totalCores=Total de núcleos
data.ExecutorSummary.totalDuration=Duración total
data.ExecutorSummary.totalGCTime=Tiempo total de GC
data.ExecutorSummary.totalInputBytes=Total de bytes de entrada
data.ExecutorSummary.totalShuffleRead=Lectura total de shuffle
data.ExecutorSummary.totalShuffleWrite=Escritura total de shuffle
data.ExecutorSummary.totalTasks=Total de tareas
data.ExecutorsAggregateInfo.activeTasks=Tareas activas
data.ExecutorsAggregateInfo.blacklisted=En la lista negra
data.ExecutorsAggregateInfo.completedTasks=Tareas completadas
data.ExecutorsAggregateInfo.diskUsed=Disco usado
data.ExecutorsAggregateInfo.failedTasks=Tareas fallidas
data.ExecutorsAggregateInfo.maxMemory=Memoria máxima
data.ExecutorsAggregateInfo.maxTasks=Máximo de tareas
data.ExecutorsAggregateInfo.memoryUsed=Memoria usada
data.ExecutorsAggregateInfo.name=Nombre
data.ExecutorsAggregateInfo.rddBlocks=Bloques RDD
data.ExecutorsAggregateInfo.totalCores=Total de núcleos
data.ExecutorsAggregateInfo.totalDuration=Duración total
data.ExecutorsAggregateInfo.totalGCTime=Tiempo total de GC
data.ExecutorsAggregateInfo.totalInputBytes=Total de bytes de entrada
data.ExecutorsAggregateInfo.totalOffHeapStorageMemory=Memoria de almacenamiento off-heap total
data.ExecutorsAggregateInfo.totalOnHeapStorageMemory=Memoria total de almacenamiento en el heap
data.ExecutorsAggregateInfo.totalShuffleRead=Total de lectura de shuffle
data.ExecutorsAggregateInfo.totalShuffleWrite=Escritura total de shuffle
data.ExecutorsAggregateInfo.totalTasks=Total de tareas
data.ExecutorsAggregateInfo.usedOffHeapStorageMemory=Memoria de almacenamiento off-heap utilizada
data.ExecutorsAggregateInfo.usedOnHeapStorageMemory=Memoria de almacenamiento on-heap usada
data.PresentableApplicationInfo.appId=ID de la aplicación
data.PresentableApplicationInfo.appSparkVersion=Versión de Spark de la aplicación
data.PresentableApplicationInfo.attemptId=ID de intento
data.PresentableApplicationInfo.duration=Duración
data.PresentableApplicationInfo.endTime=Hora de finalización
data.PresentableApplicationInfo.lastUpdated=Última actualización
data.PresentableApplicationInfo.logsUrl=URL de registros
data.PresentableApplicationInfo.name=Nombre
data.PresentableApplicationInfo.sparkUser=Usuario de Spark
data.PresentableApplicationInfo.startTime=Hora de inicio
data.PresentableApplicationInfo.status=Estado
data.RDDDataDistribution.address=Dirección
data.RDDDataDistribution.diskUsed=Disco usado
data.RDDDataDistribution.memoryRemaining=Memoria restante
data.RDDDataDistribution.memoryUsed=Memoria utilizada
data.RDDDataDistribution.offHeapMemoryRemaining=Memoria off-heap restante
data.RDDDataDistribution.offHeapMemoryUsed=Memoria off-heap utilizada
data.RDDDataDistribution.onHeapMemoryRemaining=Memoria on-heap restante
data.RDDDataDistribution.onHeapMemoryUsed=Memoria on-heap utilizada
data.RDDPartitionInfo.blockName=Nombre del bloque
data.RDDPartitionInfo.diskUsed=Disco utilizado
data.RDDPartitionInfo.executors=Ejecutores
data.RDDPartitionInfo.memoryUsed=Memoria usada
data.RDDPartitionInfo.storageLevel=Nivel de almacenamiento
data.RDDStorageInfo.diskUsed=Disco utilizado
data.RDDStorageInfo.id=ID
data.RDDStorageInfo.memoryUsed=Memoria utilizada
data.RDDStorageInfo.name=Nombre
data.RDDStorageInfo.numCachedPartitions=Número de particiones en caché
data.RDDStorageInfo.numPartitions=Número de particiones
data.RDDStorageInfo.storageLevel=Nivel de almacenamiento
data.SqlInfo.descriptionShort=Descripción corta
data.SqlInfo.duration=Duración
data.SqlInfo.failedJobs=Trabajos fallidos
data.SqlInfo.id=ID
data.SqlInfo.runningJobs=Trabajos en ejecución
data.SqlInfo.status=Estado
data.SqlInfo.submitted=Enviado
data.SqlInfo.succeededJobs=Trabajos exitosos
data.job.completionTime=Hora de finalización
data.job.id=ID del trabajo
data.job.jobGroup=Grupo de trabajos
data.job.killedTasksSummary=Resumen de tareas terminadas
data.job.name=Nombre
data.job.numActiveStages=Número de etapas activas
data.job.numActiveTasks=Número de tareas activas
data.job.numCompletedIndices=Número de índices completados
data.job.numCompletedStages=Número de etapas completadas
data.job.numCompletedTasks=Número de tareas completadas
data.job.numFailedStages=Número de etapas fallidas
data.job.numFailedTasks=Número de tareas fallidas
data.job.numKilledTasks=Número de tareas finalizadas
data.job.numSkippedStages=Número de etapas omitidas
data.job.numSkippedTasks=Número de tareas omitidas
data.job.numTasks=Número de tareas
data.job.stageIds=IDs de etapa
data.job.status=Estado
data.job.submissionTime=Hora de envío
data.job.totalStages=Total de etapas
data.job.totalTasks=Total de tareas
data.job.visualization=Visualización
data.metric.max=Máximo
data.metric.median=Mediana
data.metric.metric=Métrica
data.metric.min=Mínimo
data.metric.percentile25=Percentil 25
data.metric.percentile75=Percentil 75
data.stage.accumulatorUpdates=Actualizaciones del acumulador
data.stage.attemptId=ID de intento
data.stage.completionTime=Tiempo de finalización
data.stage.description=Descripción
data.stage.details=Detalles
data.stage.diskBytesSpilled=Bytes volcados a disco
data.stage.duration=Duración
data.stage.executorCpuTime=Tiempo de CPU del ejecutor
data.stage.executorDeserializeCpuTime=Tiempo de CPU de deserialización del ejecutor
data.stage.executorDeserializeTime=Tiempo de deserialización del ejecutor
data.stage.executorRunTime=Tiempo de ejecución del ejecutor
data.stage.executorSummary=Resumen del ejecutor
data.stage.failureReason=Motivo del fallo
data.stage.firstTaskLaunchedTime=Hora de lanzamiento de la primera tarea
data.stage.id=ID de la etapa
data.stage.inputBytes=Bytes de entrada
data.stage.inputRecords=Registros de entrada
data.stage.jvmGcTime=Tiempo de recolección de basura de la JVM
data.stage.killedTasksSummary=Resumen de tareas terminadas forzosamente
data.stage.memoryBytesSpilled=Bytes de memoria volcados
data.stage.name=Nombre
data.stage.numActiveTasks=Número de tareas activas
data.stage.numCompleteTasks=Número de tareas completadas
data.stage.numCompletedIndices=Número de índices completados
data.stage.numFailedTasks=Número de tareas fallidas
data.stage.numKilledTasks=Número de tareas terminadas
data.stage.numTasks=Número de tareas
data.stage.outputBytes=Bytes de salida
data.stage.outputRecords=Registros de salida
data.stage.peakExecutionMemory=Memoria de ejecución pico
data.stage.rddIds=IDs de RDD
data.stage.resourceProfileId=ID del perfil de recursos
data.stage.resultSerializationTime=Tiempo de serialización de resultados
data.stage.resultSize=Tamaño del resultado
data.stage.schedulingPool=Pool de planificación
data.stage.shuffleFetchWaitTime=Tiempo de espera de obtención de shuffle
data.stage.shuffleLocalBlocksFetched=Bloques de shuffle locales obtenidos
data.stage.shuffleLocalBytesRead=Bytes de shuffle leídos localmente
data.stage.shuffleReadBytes=Bytes de lectura de shuffle
data.stage.shuffleReadRecords=Registros de lectura de shuffle
data.stage.shuffleRemoteBlocksFetched=Bloques remotos de shuffle obtenidos
data.stage.shuffleRemoteBytesRead=Bytes de shuffle remoto leídos
data.stage.shuffleRemoteBytesReadToDisk=Bytes de shuffle remotos leídos a disco
data.stage.shuffleWriteBytes=Bytes de escritura de shuffle
data.stage.shuffleWriteRecords=Registros de escritura de shuffle
data.stage.shuffleWriteTime=Tiempo de escritura de shuffle
data.stage.status=Estado
data.stage.submissionTime=Hora de envío
data.stage.tasks=Tareas
data.task.accumulatorUpdates=Actualizaciones del acumulador
data.task.attempt=Intento
data.task.duration=Duración
data.task.errorMessage=Mensaje de error
data.task.executorId=ID del ejecutor
data.task.executorLogs=Logs del ejecutor
data.task.gettingResultTime=Obteniendo el tiempo de resultado
data.task.host=Anfitrión
data.task.id=ID de la tarea
data.task.index=Índice
data.task.launchTime=Hora de inicio
data.task.locality=Localidad
data.task.resultFetchStart=Inicio de la obtención de resultados
data.task.schedulerDelay=Retraso del planificador
data.task.speculative=Especulativo
data.task.status=Estado
error.message=Mensaje de error
error.title=Problema de conexión.
executors.active=Activo
executors.dead=Inactivo
executors.total=Total
exportable.SparkMonitoringSettings.presentable.name=Configuración de monitoreo de Spark de Big Data Tools
filter.app.run.by.me=Solo mis envíos
graph.cannot.navigate.text=No se encuentra el archivo "{0}" en el proyecto "{1}"
graph.cannot.navigate.title=No se puede navegar
graph.presentable.name=Diagrama DAG del trabajo
jobs.cannotFind.text=No se puede encontrar el trabajo {0}. Es posible que falten los datos del historial de Spark de este trabajo. Intente actualizar la conexión.
jobs.cannotFind.title=Trabajo no encontrado
jobs.noSelection=Nada seleccionado
link.to.download.logs=Descargar registros
notification.group.job.updates=Trabajos de Spark
notify.spark.in.history.message=La aplicación {0} está disponible en Spark History
open.app.in.services=Abrir monitoreo
open.executor.logs.not.found.popup.message=Los registros no están registrados
open.spark.app.progress.title=Abriendo aplicación Spark
open.url.tooltip=Abrir el elemento seleccionado en el navegador
process.open.logs=Abrir registros
services.spark.creating=Creando la conexión de monitorización de Spark…
services.spark.creating.cancel=Cancelar
services.spark.fix.connection=Corregir conexión SSH
services.spark.jobs.title=Trabajos de Spark
services.spark.tunnel.error=No se pudo conectar al clúster a través del túnel SSH
stages.openTasks=Abrir tareas
stages.showDetails.hint=Mostrar detalles de la etapa seleccionada
stages.showDetails.title=Mostrar detalles
stages.showTasks.hint=Mostrar las tareas de la etapa seleccionada
stages.showTasks.title=Mostrar tareas
status.active=Activo
status.complete=Completado
status.completed=Completado
status.error=Error
status.failed=Fallido
status.getResult=Obtener resultado
status.killed=Terminado
status.pending=Pendiente
status.running=En ejecución
status.skipped=Omitido
status.starting=Iniciando
status.succeeded=Completado
status.success=Éxito
status.unknown=Desconocido
tasks.hideEmptyRows=Ocultar filas vacías
tasks.showAllRow=Mostrar todas las filas
tasks.summary=Resumen de tareas
tasks.title=Tareas
title.classpath.entries=Entradas de classpath
title.hadoopProperties=Propiedades de Hadoop
title.runtime=Tiempo de ejecución
title.sparkProperties=Propiedades de Spark
title.summary=Resumen
title.systemProperties=Propiedades del sistema
toolwindow.title=Monitoreo de Spark
