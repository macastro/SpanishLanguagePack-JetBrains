action.add.job.title=Enviar trabajo
action.cancel.job.confirm.msg=¿Desea cancelar el trabajo "{0}"?
action.cancel.job.title=Cancelar trabajo
action.clone.job.title=Clonar trabajo
action.cluster.remove.confirm.msg=¿Desea eliminar el clúster "{0}"?
action.cluster.start.confirm.msg=¿Desea iniciar el clúster "{0}"?
action.cluster.terminate.confirm.msg=¿Desea terminar el clúster "{0}"?
action.confirm.title=Confirmar
action.delete.job.confirm.msg=¿Desea eliminar el trabajo "{0}"?
action.delete.job.title=Eliminar trabajo
action.open.stage.bucket=Abrir bucket de almacenamiento provisional
action.sftp=Abrir SFTP al nodo
action.sftp.master.node=Abrir SFTP al nodo maestro
action.ssh=Abrir SSH al nodo
action.ssh.master.node=Conectar al nodo maestro a través de SSH
add.job.title=Enviar trabajo
add.new.submit.connection.label=Añadir conexión de Dataproc…
cell.execution.finished.msg=El trabajo "{0}" ha finalizado con el estado {1}.
cell.execution.finished.title=Trabajo de Dataproc
cluster.action.delete=Eliminar clúster
cluster.action.start=Iniciar clúster
cluster.action.stop=Detener clúster
cluster.info.config.autoscaling=Escalado automático:
cluster.info.config.master.node.desc=Nodo maestro:
cluster.info.config.metastore=Metastore de Dataproc:
cluster.info.config.monitoring=Monitoreo de integridad:
cluster.info.config.network=Red:
cluster.info.config.region=Región:
cluster.info.config.scheduled.deletion=Eliminación programada:
cluster.info.config.secure.boot=Arranque seguro:
cluster.info.config.vtpm=VTPM:
cluster.info.config.worker.node.desc=Nodo worker:
cluster.info.config.zone=Zona
cluster.info.image.created=Fecha de creación:
cluster.info.image.version=Versión de la imagen:
cluster.info.internal.ip=Solo IP interna:
cluster.info.optional.components=Componentes opcionales:
cluster.info.summary.name=Nombre:
cluster.info.summary.state=Estado:
cluster.info.summary.state.details=Detalles del estado:
cluster.info.summary.type=Tipo:
cluster.info.summary.uiid=UUID del clúster:
cluster.tab.applications.title=Aplicaciones
cluster.tab.info.title=Información
cluster.tab.jobs.title=Trabajos
cluster.tab.name=Clúster
cluster.tab.vb.instances.title=Instancias de VM
data.clusterInfo.created=Creado
data.clusterInfo.id=ID
data.clusterInfo.name=Nombre
data.clusterInfo.region=Región
data.clusterInfo.scheduledDeletion=Eliminación programada
data.clusterInfo.stagingBucket=Bucket de almacenamiento provisional
data.clusterInfo.state=Estado
data.clusterInfo.totalWorkers=Total de workers
data.clusterInfo.zone=Zona
data.jobInfo.cluster=Clúster
data.jobInfo.elapsedTime=Tiempo transcurrido
data.jobInfo.id=ID
data.jobInfo.labels=Etiquetas
data.jobInfo.startTime=Hora de inicio
data.jobInfo.status=Estado
data.jobInfo.type=Tipo
data.vm.instanceInfo.componentGateway=Componente Gateway
data.vm.instanceInfo.name=Nombre
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=Nombre
data.web.interfaceInfo.role=Rol
datamanager.configuration=Configuración
datamanager.job.info=Información del trabajo
datamanager.labels=Etiquetas
datamanager.properties=Propiedades
datamanager.summary=Resumen
dataproc.error=Error de Dataproc
dataproc.error.cluster.must.be.started=El clúster debe estar en ejecución.
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=Proyecto GC Dataproc
emr.remove.linked.connections.title=Conexiones de Dataproc
error.connection.is.not.found=No se ha establecido una conexión para Dataproc. Por favor, vuelva a crearla.
error.json.auth.limited.msg=Esta operación solo está disponible cuando se autentica en Dataproc utilizando la CLI de gcloud
error.json.auth.limited.title=Operación no disponible
error.spark.is.not.found=El clúster no contiene Spark History Server
exportable.DataprocSettings.presentable.name=Configuración de Dataproc de Big Data Tools
exportable.DataprocSshKeyPaths.presentable.name=Configuración de SSH de Dataproc de Big Data Tools
group.name.dataproc=GC Dataproc
info.value.off=Desactivado
instance.config.gpu.number=Número de GPUs
instance.config.local.ssd=SSD local
instance.config.machineType=Tipo de máquina:
instance.config.primary.disk.size=Tamaño del disco principal:
instance.config.primary.disk.type=Tipo de disco principal:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=Etiquetas de cliente
job.info.cluster=Clúster:
job.info.continue.on.failure=Continuar en caso de fallo
job.info.elapsed.time=Tiempo transcurrido:
job.info.jobId=ID del trabajo:
job.info.jobUuid=UUID del trabajo:
job.info.max.restart.per.hour=Máximo de reinicios por hora:
job.info.max.restart.per.hour.hint=Deje en blanco si no desea que el trabajo se reinicie automáticamente en caso de fallo.
job.info.open.job.files=Mostrar carpeta del trabajo en GCS
job.info.properties=Propiedades
job.info.query.file=Consulta:
job.info.query.file.value=Archivo de consulta:
job.info.query.text.value=Texto de la consulta:
job.info.query.type=Origen de la consulta:
job.info.single.file.hint=Puede ser un archivo de GCS con el prefijo gs://, un archivo de HDFS en el clúster con el prefijo hdfs:// o un archivo local en el clúster con el prefijo file://
job.info.spark.additional.py.files=Archivos Python adicionales:
job.info.spark.additional.py.files.title=Seleccionar archivos Py adicionales
job.info.spark.additional.r.files=Archivos R adicionales:
job.info.spark.additional.r.files.title=Seleccionar archivos R adicionales
job.info.spark.archives=Archivos:
job.info.spark.archives.hint=Los archivos de almacenamiento se extraen en el directorio de trabajo de Spark. Pueden ser archivos GCS con el prefijo gs://, archivos HDFS en el clúster con el prefijo hdfs:// o archivos locales en el clúster con el prefijo file://. Los tipos de archivos admitidos son: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Seleccionar archivos
job.info.spark.args=Argumentos:
job.info.spark.files=Archivos:
job.info.spark.jars=Jar:
job.info.spark.jars.hint=Los archivos Jar se incluyen en el CLASSPATH. Pueden ser archivos GCS con el prefijo gs://, archivos HDFS con el prefijo hdfs:// en el clúster o archivos locales con el prefijo file:// en el clúster.
job.info.spark.jars.title=JAR
job.info.spark.main.class=Clase principal:
job.info.spark.main.py.file.title=Seleccionar archivo Py principal
job.info.spark.main.pyfile=Archivo Python principal:
job.info.spark.main.r.file=Archivo R principal:
job.info.spark.main.r.file.title=Seleccionar el archivo R principal
job.info.start.date=Fecha de inicio:
job.info.status=Estado:
job.info.status.details=Detalles del estado:
job.info.type=Tipo de trabajo:
job.label.block.title=Etiqueta
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=Propiedades
job.pyspark.title=PySpark
job.query.file.dialog.title=Seleccionar archivo de consulta:
job.query.file.label=Archivo de consulta:
job.query.source.file=Archivo
job.query.source.text=Texto
job.query.source.type=Tipo de consulta:
job.query.text.hint=Consulta a ejecutar
job.query.text.label=Texto de la consulta:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=Activo
job.state.canceled=Cancelado
job.state.done=Completado
job.state.failed=Fallido
job.validation.file.archive={0} debe ser un tipo de archivo .jar, .tar, .tar.gz, .tgz, .zip.
job.validation.file.fs={0} debe ser un archivo con el prefijo gs://, hdfs:// o file://
metainfo.cluster.id=ID:
metainfo.cluster.name=Nombre:
metainfo.cluster.status=Estado:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=No se admite la detección de la clase principal de {0}.
settings.application.class.name.error.msg=Seleccione primero el archivo JAR
task.init.ssh.perform.cli.command=Ejecutando comando GCloud CLI…
task.init.ssh.title=Ejecución de Dataproc CLI
