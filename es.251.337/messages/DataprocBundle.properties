action.add.job.title=Enviar trabajo
action.cancel.job.confirm.msg=¿Desea cancelar el trabajo "{0}"?
action.cancel.job.title=Cancelar trabajo
action.clone.job.title=Clonar trabajo
action.cluster.remove.confirm.msg=¿Desea eliminar el clúster "{0}"?
action.cluster.start.confirm.msg=¿Desea iniciar el clúster "{0}"?
action.cluster.terminate.confirm.msg=¿Desea terminar el clúster "{0}"?
action.confirm.title=Confirmar
action.delete.job.confirm.msg=¿Desea eliminar el trabajo "{0}"?
action.delete.job.title=Eliminar trabajo
action.open.stage.bucket=Abrir bucket de almacenamiento temporal
action.sftp=Abrir SFTP al nodo
action.sftp.master.node=Abrir SFTP al nodo maestro
action.ssh=Abrir SSH al nodo
action.ssh.master.node=Conectar por SSH al nodo maestro
add.job.title=Enviar trabajo
add.new.submit.connection.label=Agregar conexión Dataproc...
cell.execution.finished.msg=El trabajo "{0}" ha finalizado con estado {1}.
cell.execution.finished.title=Trabajo Dataproc
cluster.action.delete=Eliminar clúster
cluster.action.start=Iniciar clúster
cluster.action.stop=Terminar clúster
cluster.info.config.autoscaling=Autoescalado\:
cluster.info.config.master.node.desc=Nodo maestro\:
cluster.info.config.metastore=Metastore Dataproc\:
cluster.info.config.monitoring=Monitoreo de integridad\:
cluster.info.config.network=Red\:
cluster.info.config.region=Región\:
cluster.info.config.scheduled.deletion=Eliminación programada\:
cluster.info.config.secure.boot=Secure Boot\:
cluster.info.config.vtpm=VTPM\:
cluster.info.config.worker.node.desc=Nodos worker\:
cluster.info.config.zone=Zona
cluster.info.image.created=Creado\:
cluster.info.image.version=Versión de imagen\:
cluster.info.internal.ip=Solo IP interna\:
cluster.info.optional.components=Componentes opcionales\:
cluster.info.summary.name=Nombre\:
cluster.info.summary.state=Estado\:
cluster.info.summary.state.details=Detalles del estado\:
cluster.info.summary.type=Tipo\:
cluster.info.summary.uiid=UUID del clúster\:
cluster.tab.applications.title=Aplicaciones
cluster.tab.info.title=Información
cluster.tab.jobs.title=Trabajos
cluster.tab.name=Clúster
cluster.tab.vb.instances.title=Instancias VM
data.clusterInfo.created=Creado
data.clusterInfo.id=ID
data.clusterInfo.name=Nombre
data.clusterInfo.region=Región
data.clusterInfo.scheduledDeletion=Eliminación programada
data.clusterInfo.stagingBucket=Bucket de almacenamiento temporal
data.clusterInfo.state=Estado
data.clusterInfo.totalWorkers=Total de workers
data.clusterInfo.zone=Zona
data.jobInfo.cluster=Clúster
data.jobInfo.elapsedTime=Tiempo transcurrido
data.jobInfo.id=ID
data.jobInfo.labels=Etiquetas
data.jobInfo.startTime=Hora de inicio
data.jobInfo.status=Estado
data.jobInfo.type=Agrupar por tipo
data.vm.instanceInfo.componentGateway=Component Gateway
data.vm.instanceInfo.name=Nombre
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=Nombre
data.web.interfaceInfo.role=Rol
datamanager.configuration=Configuración
datamanager.job.info=Información del trabajo
datamanager.labels=Etiquetas
datamanager.properties=Propiedades
datamanager.summary=Resumen
dataproc.error=Error de Dataproc
dataproc.error.cluster.must.be.started=El clúster debe estar en ejecución.
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=Proyecto GC Dataproc
emr.remove.linked.connections.title=Conexión Dataproc
error.connection.is.not.found=No hay conexión configurada para Dataproc. Por favor, créela nuevamente.
error.json.auth.limited.msg=Esta operación solo está disponible cuando se autentica en Dataproc usando gcloud CLI
error.json.auth.limited.title=Operación no disponible
error.spark.is.not.found=El clúster no contiene Spark History Server
exportable.DataprocSettings.presentable.name=Configuración Big Data Tools Dataproc
exportable.DataprocSshKeyPaths.presentable.name=Configuración SSH Big Data Tools Dataproc
group.name.dataproc=GC Dataproc
info.value.off=Desactivado
instance.config.gpu.number=Número de GPUs
instance.config.local.ssd=SSD local
instance.config.machineType=Tipo de máquina\:
instance.config.primary.disk.size=Tamaño del disco principal\:
instance.config.primary.disk.type=Tipo de disco principal\:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=Tags del cliente
job.info.cluster=Clúster\:
job.info.continue.on.failure=Continuar en caso de fallo
job.info.elapsed.time=Tiempo transcurrido\:
job.info.jobId=ID del trabajo\:
job.info.jobUuid=UUID del trabajo\:
job.info.max.restart.per.hour=Máximo de reinicios por hora\:
job.info.max.restart.per.hour.hint=Dejar vacío si no desea reinicio automático cuando el trabajo falle.
job.info.open.job.files=Mostrar carpeta del trabajo en GCS
job.info.properties=Propiedades
job.info.query.file=Consulta\:
job.info.query.file.value=Archivo de consulta\:
job.info.query.text.value=Texto de consulta\:
job.info.query.type=Origen de consulta\:
job.info.single.file.hint=Puede ser un archivo GCS con prefijo gs\://, un archivo HDFS en el clúster con prefijo hdfs\:// o un archivo local en el clúster con prefijo file\://
job.info.spark.additional.py.files=Archivos Python adicionales\:
job.info.spark.additional.py.files.title=Seleccionar archivos Py adicionales
job.info.spark.additional.r.files=Archivos R adicionales\:
job.info.spark.additional.r.files.title=Seleccionar archivos R adicionales
job.info.spark.archives=Archivos\:
job.info.spark.archives.hint=Los archivos se extraen en el directorio de trabajo de Spark. Puede ser un archivo GCS con prefijo gs\://, un archivo HDFS en el clúster con prefijo hdfs\:// o un archivo local en el clúster con prefijo file\://. Los tipos de archivo soportados son\: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Seleccionar archivos
job.info.spark.args=Argumentos\:
job.info.spark.files=Archivos\:
job.info.spark.jars=Jar\:
job.info.spark.jars.hint=Los archivos Jar se incluyen en el CLASSPATH. Puede ser un archivo GCS con prefijo gs\://, un archivo HDFS en el clúster con prefijo hdfs\:// o un archivo local en el clúster con prefijo file\://.
job.info.spark.jars.title=JAR
job.info.spark.main.class=Clase principal\:
job.info.spark.main.py.file.title=Seleccionar archivo Py principal
job.info.spark.main.pyfile=Archivo Python principal\:
job.info.spark.main.r.file=Archivo R principal\:
job.info.spark.main.r.file.title=Seleccionar archivo R principal
job.info.start.date=Fecha de inicio\:
job.info.status=Estado\:
job.info.status.details=Detalles del estado\:
job.info.type=Tipo de trabajo\:
job.label.block.title=Etiquetas
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=Propiedades
job.pyspark.title=PySpark
job.query.file.dialog.title=Seleccionar archivo de consulta\:
job.query.file.label=Archivo de consulta\:
job.query.source.file=Archivo
job.query.source.text=Texto
job.query.source.type=Tipo de consulta\:
job.query.text.hint=Consulta a ejecutar
job.query.text.label=Texto de consulta\:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=Activo
job.state.canceled=Cancelado
job.state.done=Completado
job.state.failed=Fallido
job.validation.file.archive={0} debe ser un archivo de tipo .jar, .tar, .tar.gz, .tgz, .zip.
job.validation.file.fs={0} debe ser un archivo con prefijo gs\://, hdfs\:// o file\://
metainfo.cluster.id=ID\:
metainfo.cluster.name=Nombre\:
metainfo.cluster.status=Estado\:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=No se admite la detección de clase principal para {0}.
settings.application.class.name.error.msg=Por favor, seleccione primero un archivo jar
task.init.ssh.perform.cli.command=Ejecutando comando GCloud CLI...
task.init.ssh.title=Ejecución CLI Dataproc