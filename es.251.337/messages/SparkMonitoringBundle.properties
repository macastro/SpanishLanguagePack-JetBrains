action.show.execution.graph=Mostrar
action.text.filter.state=Filtrar estado
action.titile.copy.logs=Copiar logs
app.run.by.me=Enviado por mí
applications.filter.finished=Finalizado
applications.filter.limit=Límite
applications.filter.name=Filtro\:
applications.filter.started=Iniciado
applications.tab.console=Consola
applications.tab.details=Detalles
applications.tab.environment=Entorno
applications.tab.executors=Ejecutores
applications.tab.info=Información
applications.tab.jobs=Jobs
applications.tab.sql=SQL
applications.tab.stages=Etapas
applications.tab.storage=Almacenamiento
applications.tab.storage.distribution=Distribución de datos
applications.tab.storage.distribution.toggle.hint=Cambiar visibilidad de la tabla de distribución de datos para el almacenamiento seleccionado
applications.tab.storage.partitions=Particiones
applications.tab.storage.partitions.toggle.hint=Cambiar visibilidad de la tabla de particiones para el almacenamiento seleccionado
column.show.logs=Logs
connection.defaultName=Monitor Spark {0}
connection.group.name.spark=Spark
data.ExecutorSummary.active=Activo
data.ExecutorSummary.activeTasks=Tareas activas
data.ExecutorSummary.addTime=Tiempo de adición
data.ExecutorSummary.address=Dirección
data.ExecutorSummary.attributes=Atributos
data.ExecutorSummary.blacklisted=En lista negra
data.ExecutorSummary.blacklistedInStages=En lista negra en etapas
data.ExecutorSummary.completedTasks=Tareas completadas
data.ExecutorSummary.diskUsed=Disco usado
data.ExecutorSummary.failedTasks=Tareas fallidas
data.ExecutorSummary.id=ID
data.ExecutorSummary.maxMemory=Memoria máxima
data.ExecutorSummary.maxTasks=Tareas máximas
data.ExecutorSummary.memoryMetrics=Métricas de memoria
data.ExecutorSummary.memoryUsed=Memoria usada
data.ExecutorSummary.rddBlocks=Bloques RDD
data.ExecutorSummary.removeReason=Razón de eliminación
data.ExecutorSummary.removeTime=Tiempo de eliminación
data.ExecutorSummary.resourceProfileId=ID de perfil de recursos
data.ExecutorSummary.resources=Recursos
data.ExecutorSummary.totalCores=Total de núcleos
data.ExecutorSummary.totalDuration=Duración total
data.ExecutorSummary.totalGCTime=Tiempo total de GC
data.ExecutorSummary.totalInputBytes=Total de bytes de entrada
data.ExecutorSummary.totalShuffleRead=Total de shuffle read
data.ExecutorSummary.totalShuffleWrite=Total de shuffle write
data.ExecutorSummary.totalTasks=Total de tareas
data.ExecutorsAggregateInfo.activeTasks=Tareas activas
data.ExecutorsAggregateInfo.blacklisted=En lista negra
data.ExecutorsAggregateInfo.completedTasks=Tareas completadas
data.ExecutorsAggregateInfo.diskUsed=Disco usado
data.ExecutorsAggregateInfo.failedTasks=Tareas fallidas
data.ExecutorsAggregateInfo.maxMemory=Memoria máxima
data.ExecutorsAggregateInfo.maxTasks=Tareas máximas
data.ExecutorsAggregateInfo.memoryUsed=Memoria usada
data.ExecutorsAggregateInfo.name=Nombre
data.ExecutorsAggregateInfo.rddBlocks=Bloques RDD
data.ExecutorsAggregateInfo.totalCores=Total de núcleos
data.ExecutorsAggregateInfo.totalDuration=Duración total
data.ExecutorsAggregateInfo.totalGCTime=Tiempo total de GC
data.ExecutorsAggregateInfo.totalInputBytes=Total de bytes de entrada
data.ExecutorsAggregateInfo.totalOffHeapStorageMemory=Memoria total de almacenamiento off-heap
data.ExecutorsAggregateInfo.totalOnHeapStorageMemory=Memoria total de almacenamiento on-heap
data.ExecutorsAggregateInfo.totalShuffleRead=Total de shuffle read
data.ExecutorsAggregateInfo.totalShuffleWrite=Total de shuffle write
data.ExecutorsAggregateInfo.totalTasks=Total de tareas
data.ExecutorsAggregateInfo.usedOffHeapStorageMemory=Memoria de almacenamiento off-heap usada
data.ExecutorsAggregateInfo.usedOnHeapStorageMemory=Memoria de almacenamiento on-heap usada
data.PresentableApplicationInfo.appId=ID de aplicación
data.PresentableApplicationInfo.appSparkVersion=Versión Spark de la aplicación
data.PresentableApplicationInfo.attemptId=ID de intento
data.PresentableApplicationInfo.duration=Duración
data.PresentableApplicationInfo.endTime=Tiempo de finalización
data.PresentableApplicationInfo.lastUpdated=Última actualización
data.PresentableApplicationInfo.logsUrl=URL de logs
data.PresentableApplicationInfo.name=Nombre
data.PresentableApplicationInfo.sparkUser=Usuario Spark
data.PresentableApplicationInfo.startTime=Tiempo de inicio
data.PresentableApplicationInfo.status=Estado
data.RDDDataDistribution.address=Dirección
data.RDDDataDistribution.diskUsed=Disco usado
data.RDDDataDistribution.memoryRemaining=Memoria restante
data.RDDDataDistribution.memoryUsed=Memoria usada
data.RDDDataDistribution.offHeapMemoryRemaining=Memoria off-heap restante
data.RDDDataDistribution.offHeapMemoryUsed=Memoria off-heap usada
data.RDDDataDistribution.onHeapMemoryRemaining=Memoria on-heap restante
data.RDDDataDistribution.onHeapMemoryUsed=Memoria on-heap usada
data.RDDPartitionInfo.blockName=Nombre de bloque
data.RDDPartitionInfo.diskUsed=Disco usado
data.RDDPartitionInfo.executors=Ejecutores
data.RDDPartitionInfo.memoryUsed=Memoria usada
data.RDDPartitionInfo.storageLevel=Nivel de almacenamiento
data.RDDStorageInfo.diskUsed=Disco usado
data.RDDStorageInfo.id=ID
data.RDDStorageInfo.memoryUsed=Memoria usada
data.RDDStorageInfo.name=Nombre
data.RDDStorageInfo.numCachedPartitions=Número de particiones en caché
data.RDDStorageInfo.numPartitions=Número de particiones
data.RDDStorageInfo.storageLevel=Nivel de almacenamiento
data.SqlInfo.descriptionShort=Descripción corta
data.SqlInfo.duration=Duración
data.SqlInfo.failedJobs=Jobs fallidos
data.SqlInfo.id=ID
data.SqlInfo.runningJobs=Jobs en ejecución
data.SqlInfo.status=Estado
data.SqlInfo.submitted=Enviado
data.SqlInfo.succeededJobs=Jobs exitosos
data.job.completionTime=Tiempo de finalización
data.job.id=ID de job
data.job.jobGroup=Grupo de job
data.job.killedTasksSummary=Resumen de tareas terminadas
data.job.name=Nombre
data.job.numActiveStages=Número de etapas activas
data.job.numActiveTasks=Número de tareas activas
data.job.numCompletedIndices=Número de índices completados
data.job.numCompletedStages=Número de etapas completadas
data.job.numCompletedTasks=Número de tareas completadas
data.job.numFailedStages=Número de etapas fallidas
data.job.numFailedTasks=Número de tareas fallidas
data.job.numKilledTasks=Número de tareas terminadas
data.job.numSkippedStages=Número de etapas omitidas
data.job.numSkippedTasks=Número de tareas omitidas
data.job.numTasks=Número de tareas
data.job.stageIds=IDs de etapa
data.job.status=Estado
data.job.submissionTime=Tiempo de envío
data.job.totalStages=Total de etapas
data.job.totalTasks=Total de tareas
data.job.visualization=Visualización
data.metric.max=Máximo
data.metric.median=Mediana
data.metric.metric=Métrica
data.metric.min=Mínimo
data.metric.percentile25=Percentil 25
data.metric.percentile75=Percentil 75
data.stage.accumulatorUpdates=Actualizaciones del acumulador
data.stage.attemptId=ID de intento
data.stage.completionTime=Tiempo de finalización
data.stage.description=Descripción
data.stage.details=Detalles
data.stage.diskBytesSpilled=Bytes derramados a disco
data.stage.duration=Duración
data.stage.executorCpuTime=Tiempo de CPU del executor
data.stage.executorDeserializeCpuTime=Tiempo de CPU de deserialización del executor
data.stage.executorDeserializeTime=Tiempo de deserialización del executor
data.stage.executorRunTime=Tiempo de ejecución del executor
data.stage.executorSummary=Resumen del executor
data.stage.failureReason=Motivo del fallo
data.stage.firstTaskLaunchedTime=Tiempo de inicio de primera tarea
data.stage.id=ID de etapa
data.stage.inputBytes=Bytes de entrada
data.stage.inputRecords=Registros de entrada
data.stage.jvmGcTime=Tiempo de garbage collection JVM
data.stage.killedTasksSummary=Resumen de tareas terminadas
data.stage.memoryBytesSpilled=Bytes derramados a memoria
data.stage.name=Nombre
data.stage.numActiveTasks=Número de tareas activas
data.stage.numCompleteTasks=Número de tareas completadas
data.stage.numCompletedIndices=Número de índices completados
data.stage.numFailedTasks=Número de tareas fallidas
data.stage.numKilledTasks=Número de tareas terminadas
data.stage.numTasks=Número de tareas
data.stage.outputBytes=Bytes de salida
data.stage.outputRecords=Registros de salida
data.stage.peakExecutionMemory=Pico de memoria de ejecución
data.stage.rddIds=ID de RDD
data.stage.resourceProfileId=ID de perfil de recursos
data.stage.resultSerializationTime=Tiempo de serialización de resultados
data.stage.resultSize=Tamaño del resultado
data.stage.schedulingPool=Pool de scheduling
data.stage.shuffleFetchWaitTime=Tiempo de espera de fetch shuffle
data.stage.shuffleLocalBlocksFetched=Bloques locales fetch shuffle
data.stage.shuffleLocalBytesRead=Bytes locales leídos shuffle
data.stage.shuffleReadBytes=Bytes leídos shuffle
data.stage.shuffleReadRecords=Registros leídos shuffle
data.stage.shuffleRemoteBlocksFetched=Bloques remotos fetch shuffle
data.stage.shuffleRemoteBytesRead=Bytes remotos leídos shuffle
data.stage.shuffleRemoteBytesReadToDisk=Bytes remotos leídos a disco shuffle
data.stage.shuffleWriteBytes=Bytes escritos shuffle
data.stage.shuffleWriteRecords=Registros escritos shuffle
data.stage.shuffleWriteTime=Tiempo de escritura shuffle
data.stage.status=Estado
data.stage.submissionTime=Tiempo de envío
data.stage.tasks=Tareas
data.task.accumulatorUpdates=Actualizaciones del acumulador
data.task.attempt=Intento
data.task.duration=Duración
data.task.errorMessage=Mensaje de error
data.task.executorId=ID del executor
data.task.executorLogs=Logs del executor
data.task.gettingResultTime=Tiempo de obtención de resultados
data.task.host=Host
data.task.id=ID de tarea
data.task.index=Índice
data.task.launchTime=Tiempo de inicio
data.task.locality=Localidad
data.task.resultFetchStart=Inicio de fetch de resultados
data.task.schedulerDelay=Retraso del scheduler
data.task.speculative=Especulativo
data.task.status=Estado
error.message=Mensaje de error
error.title=Problema de conexión.
executors.active=Activos
executors.dead=Inactivos
executors.total=Total
exportable.SparkMonitoringSettings.presentable.name=Configuración de monitoreo Spark de Big Data Tools
filter.app.run.by.me=Solo enviados por mí
graph.cannot.navigate.text=No se encuentra el archivo "{0}" en el proyecto "{1}"
graph.cannot.navigate.title=No se puede navegar
graph.presentable.name=Gráfico DAG de jobs
jobs.cannotFind.text=No se encuentra el job {0}. Los datos históricos de Spark para este job pueden haberse perdido. Intente refrescar la conexión.
jobs.cannotFind.title=Job no encontrado
jobs.noSelection=Nada seleccionado
link.to.download.logs=Descargar logs
notification.group.job.updates=Jobs Spark
notify.spark.in.history.message=Aplicación {0} disponible en el historial de Spark
open.app.in.services=Abrir monitoreo
open.executor.logs.not.found.popup.message=Logs no registrados
open.spark.app.progress.title=Abriendo aplicación Spark
open.url.tooltip=Abrir elemento seleccionado en el navegador
process.open.logs=Abrir logs
services.spark.creating=Creando conexión de monitoreo Spark...
services.spark.creating.cancel=Cancelar
services.spark.fix.connection=Corregir conexión SSH
services.spark.jobs.title=Jobs Spark
services.spark.tunnel.error=No se puede conectar al cluster a través del túnel SSH
stages.openTasks=Abrir tareas
stages.showDetails.hint=Mostrar detalles de la etapa seleccionada
stages.showDetails.title=Mostrar detalles
stages.showTasks.hint=Mostrar tareas de la etapa seleccionada
stages.showTasks.title=Mostrar tareas
status.active=Activo
status.complete=Completo
status.completed=Completado
status.error=Error
status.failed=Fallido
status.getResult=Obtener resultado
status.killed=Terminado
status.pending=Pendiente
status.running=Ejecutando
status.skipped=Omitido
status.starting=Iniciando
status.succeeded=Exitoso
status.success=Éxito
status.unknown=Desconocido
tasks.hideEmptyRows=Ocultar filas vacías
tasks.showAllRow=Mostrar todas las filas
tasks.summary=Resumen de tareas
tasks.title=Tareas
title.classpath.entries=Entradas del classpath
title.hadoopProperties=Propiedades de Hadoop
title.runtime=Runtime
title.sparkProperties=Propiedades de Spark
title.summary=Resumen
title.systemProperties=Propiedades del sistema
toolwindow.title=Monitoreo Spark